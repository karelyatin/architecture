#
# CHANGEME:
#
# - Change "spec.baremetalSetTemplate.ctlplaneInterface" to be the control plane
#   interface on your compute nodes
# - Change "spec.baremetalSetTemplate.provisioningInterface" to be the provisioning
#   interface used by Metal3 on your OpenShift nodes
# - Change the interface name specified in "spec.nodeTemplate.ansible.ansibleVars.edpm_network_config_template"
#   to be the control plane interface on your compute nodes
#     i.e.
#     members:
#     - type: interface
#       name: enp7s0    <---- change
# - Change "spec.nodeTemplate.ansible.ansibleVars.edpm_sshd_allowed_ranges[0]" to 
#   match the CIDR of your control plane network, if necessary
# - Change "edpm_bootstrap_command" to include subscription-manager and podman login
#   commands to register the EDPM nodes as in https://access.redhat.com/solutions/253273
#
# EXTERNAL DEPENDENCIES:
#
# - "spec.nodes" lists 3 nodes that will require 3 metal3.io/v1alpha1 BareMetalHost resources, 
#   which are the user's responsibility to have added to the cluster ahead of time.  They also 
#   must be labelled "app: openstack" for the purposes of this OpenStackDataPlaneNodeSet
#   (see "spec.baremetalSetTemplate.bmhLabelSelector", which can be changed if you wish to use
#    a different label for BareMetalHost selection).
#

apiVersion: dataplane.openstack.org/v1beta1
kind: OpenStackDataPlaneNodeSet
metadata:
  name: openstack-edpm-ipam
  namespace: openstack
spec:
  baremetalSetTemplate:
    bmhLabelSelector:
      app: openstack
    bmhNamespace: openshift-machine-api
    cloudUserName: cloud-admin
    ctlplaneInterface: enp3s0
    passwordSecret:
      name: baremetalset-password-secret
      namespace: openstack
    provisioningInterface: enp1s0
  env:
    - name: ANSIBLE_CALLBACKS_ENABLED
      value: profile_tasks
    - name: ANSIBLE_FORCE_COLOR
      value: "True"
    - name: ANSIBLE_ENABLE_TASK_DEBUGGER
      value: "True"
  networkAttachments:
    - ctlplane
  nodeTemplate:
    ansible:
      ansiblePort: 22
      ansibleUser: cloud-admin
      ansibleVars:
        edpm_chrony_ntp_servers:
          - clock.redhat.com
        # CHANGEME -- see https://access.redhat.com/solutions/253273
        # edpm_bootstrap_command: |
        #       subscription-manager register --username <subscription_manager_username> --password <subscription_manager_password>
        #       podman login -u <registry_username> -p <registry_password> registry.redhat.io
        edpm_iscsid_image: '{{ registry_url }}/openstack-iscsid:{{ image_tag }}'
        edpm_logrotate_crond_image: '{{ registry_url }}/openstack-cron:{{ image_tag }}'
        edpm_network_config_hide_sensitive_logs: false
        edpm_network_config_template: |
          ---
          {% set mtu_list = [ctlplane_mtu] %}
          {% for network in role_networks %}
          {{ mtu_list.append(lookup('vars', networks_lower[network] ~ '_mtu')) }}
          {%- endfor %}
          {% set min_viable_mtu = mtu_list | max %}
          network_config:
          - type: ovs_bridge
            name: {{ neutron_physical_bridge_name }}
            mtu: {{ min_viable_mtu }}
            use_dhcp: false
            dns_servers: {{ ctlplane_dns_nameservers }}
            domain: {{ dns_search_domains }}
            addresses:
            - ip_netmask: {{ ctlplane_ip }}/{{ ctlplane_subnet_cidr }}
            routes: {{ ctlplane_host_routes }}
            members:
            - type: interface
              name: enp3s0
              mtu: {{ min_viable_mtu }}
              # force the MAC address of the bridge to this interface
              primary: true
          {% for network in role_networks %}
            - type: vlan
              mtu: {{ lookup('vars', networks_lower[network] ~ '_mtu') }}
              vlan_id: {{ lookup('vars', networks_lower[network] ~ '_vlan_id') }}
              addresses:
              - ip_netmask:
                  {{ lookup('vars', networks_lower[network] ~ '_ip') }}/{{ lookup('vars', networks_lower[network] ~ '_cidr') }}
              routes: {{ lookup('vars', networks_lower[network] ~ '_host_routes') }}
          {% endfor %}
        edpm_neutron_metadata_agent_image: '{{ registry_url }}/openstack-neutron-metadata-agent-ovn:{{ image_tag }}'
        edpm_nodes_validation_validate_controllers_icmp: false
        edpm_nodes_validation_validate_gateway_icmp: false
        edpm_nova_compute_container_image: '{{ registry_url }}/openstack-nova-compute:{{ image_tag }}'
        edpm_nova_libvirt_container_image: '{{ registry_url }}/openstack-nova-libvirt:{{ image_tag }}'
        edpm_ovn_controller_agent_image: '{{ registry_url }}/openstack-ovn-controller:{{ image_tag }}'
        edpm_selinux_mode: enforcing
        edpm_sshd_allowed_ranges:
          - 192.168.122.0/24
        edpm_sshd_configure_firewall: true
        enable_debug: false
        gather_facts: false
        image_tag: current-podified
        neutron_physical_bridge_name: br-ex
        neutron_public_interface_name: eth0
        registry_url: quay.io/podified-antelope-centos9
        service_net_map:
          nova_api_network: internal_api
          nova_libvirt_network: internal_api
        edpm_ceph_hci_pre_enabled_services:
          - ceph_mon
          - ceph_mgr
          - ceph_osd
          - ceph_rgw
          - ceph_nfs
          - ceph_rgw_frontend
          - ceph_nfs_frontend
        storage_mtu: 1500
        storage_mgmt_mtu: 1500
        storage_mgmt_vlan_id: 23
        storage_mgmt_cidr: "24"
        storage_mgmt_host_routes: []
    ansibleSSHPrivateKeySecret: dataplane-ansible-ssh-private-key-secret
    managementNetwork: ctlplane
    networks:
      - defaultRoute: true
        name: CtlPlane
        subnetName: subnet1
      - name: InternalApi
        subnetName: subnet1
      - name: Storage
        subnetName: subnet1
      - name: Tenant
        subnetName: subnet1
      - name: StorageMgmt
        subnetName: subnet1
  nodes:
    edpm-compute-0:
      hostName: edpm-compute-0
    edpm-compute-1:
      hostName: edpm-compute-1
    edpm-compute-2:
      hostName: edpm-compute-2
  # Each OpenStackDataPlaneDeployment will override
  # the services list so that only a subset of them
  # are deployed during different phases. The full
  # service list is defined here so that each service
  # will be created by the dataplane-operator.
  services:
    - configure-network
    - validate-network
    - install-os
    - ceph-hci-pre
    - configure-os
    - run-os
    - ceph-client
    - ovn
    - neutron-metadata
    - libvirt
    - nova-custom-ceph
